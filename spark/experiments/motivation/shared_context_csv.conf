spark-bench = {
  spark-submit-parallel = false
  spark-submit-config = [{
    spark-args = {
      master = "spark://silver-spark-master-svc.silver.svc.cluster.local:7077"
      executor-memory = "3712M"
      total-executor-cores = "10"
      executor-cores = "5"
      //driver-memory = "14G"
      //deploy-mode = "cluster"
      //num-executors = 2
    }
    conf = {
      "spark.eventLog.enabled" = "true"
      "spark.eventLog.dir" = "./spark_data/1"
      "spark.memory.storageFraction" = 0.90
      "spark.executor.memoryOverhead" = "384M"
      //"spark.driver.memoryOverhead" = "384M"
      //spark.sql.shuffle.partitions = 500
      //spark.default.parallelism = 500
      //spark.executor.extraJavaOptions = "-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
      //spark.driver.extraJavaOptions = "-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
      //spark.dynamicAllocation.enabled = "true"
      //spark.shuffle.service.enabled = "true"
    }
    suites-parallel = true
    workload-suites = [
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-1.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data1.csv"]
            query = ["select c0, c6 from input where c0 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-1.parquet"
            save-mode = "overwrite"
          }
        ]

     },
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-2.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data2.csv"]
            query = ["select c0, c7, c6 from input where c0 < -0.9 and c7 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-2.parquet"
            save-mode = "overwrite"
          }
        ]

     },
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-3.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data3.csv"]
            query = ["select c0, c7, c8, c6 from input where c0 < -0.9 and c7 < -0.9 and c8 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-3.parquet"
            save-mode = "overwrite"
          }
        ]

     },
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-4.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data4.csv"]
            query = ["select c0, c7, c8, c9, c6 from input where c0 < -0.9 and c7 < -0.9 and c8 < -0.9 and c9 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-4.parquet"
            save-mode = "overwrite"
          }
        ]

     },
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-5.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data5.csv"]
            query = ["select c0, c7, c8, c9, c10, c6 from input where c0 < -0.9 and c7 < -0.9 and c8 < -0.9 and c9 < -0.9 and c10 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-5.parquet"
            save-mode = "overwrite"
          }
        ]

     },
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-6.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data6.csv"]
            query = ["select c0, c7, c8, c9, c10, c11, c6 from input where c0 < -0.9 and c7 < -0.9 and c8 < -0.9 and c9 < -0.9 and c10 < -0.9 and c11 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-6.parquet"
            save-mode = "overwrite"
          }
        ]

     },
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-7.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data7.csv"]
            query = ["select c0, c7, c8, c9, c10, c11, c12, c6 from input where c0 < -0.9 and c7 < -0.9 and c8 < -0.9 and c9 < -0.9 and c10 < -0.9 and c11 < -0.9 and c12 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-7.parquet"
            save-mode = "overwrite"
          }
        ]

     },
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-8.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data8.csv"]
            query = ["select c0, c7, c8, c9, c10, c11, c12, c13, c6 from input where c0 < -0.9 and c7 < -0.9 and c8 < -0.9 and c9 < -0.9 and c10 < -0.9 and c11 < -0.9 and c12 < -0.9 and c13 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-8.parquet"
            save-mode = "overwrite"
          }
        ]

     },
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-9.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data9.csv"]
            query = ["select c0, c7, c8, c9, c10, c11, c12, c13, c14, c6 from input where c0 < -0.9 and c7 < -0.9 and c8 < -0.9 and c9 < -0.9 and c10 < -0.9 and c11 < -0.9 and c12 < -0.9 and c13 < -0.9 and c14 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-9.parquet"
            save-mode = "overwrite"
          }
        ]

     },
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-10.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data10.csv"]
            query = ["select c0, c7, c8, c9, c10, c11, c12, c13, c14, c15, c6 from input where c0 < -0.9 and c7 < -0.9 and c8 < -0.9 and c9 < -0.9 and c10 < -0.9 and c11 < -0.9 and c12 < -0.9 and c13 < -0.9 and c14 < -0.9 and c15 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-10.parquet"
            save-mode = "overwrite"
          }
        ]

     }
   ]
  }]
}
