spark-bench = {
  spark-submit-parallel = true
  spark-submit-config = [{
    spark-args = {
      master = "spark://silver-spark-master-svc.silver.svc.cluster.local:7077"
      executor-memory = "3712M"
      total-executor-cores = "5"
      executor-cores = "5"
      //driver-memory = "14G"
      //deploy-mode = "cluster"
      //num-executors = 2
    }
    conf = {
      "spark.eventLog.enabled" = "true"
      "spark.eventLog.dir" = "./spark_data/1"
      "spark.memory.storageFraction" = 0.90
      "spark.executor.memoryOverhead" = "384M"
      //"spark.driver.memoryOverhead" = "384M" 
      //spark.sql.shuffle.partitions = 500
      //spark.default.parallelism = 500
      //spark.executor.extraJavaOptions = "-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
      //spark.driver.extraJavaOptions = "-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
      //spark.dynamicAllocation.enabled = "true"
      //spark.shuffle.service.enabled = "true"
    }
    suites-parallel = false
    workload-suites = [
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-1.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data1.csv", "file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data-g2-1.parquet"]
            query = ["select * from input", "select c0, c6 from input where c0 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-1.parquet"
            save-mode = "overwrite"
          }
        ]
     }
    ]
  },
  {
    spark-args = {
      master = "spark://silver-spark-master-svc.silver.svc.cluster.local:7077"
      executor-memory = "3712M"
      total-executor-cores = "5"
      executor-cores = "5"
      //driver-memory = "14G"
      //deploy-mode = "cluster"
      //num-executors = 2
    }
    conf = {
      "spark.eventLog.enabled" = "true"
      "spark.eventLog.dir" = "./spark_data/1"
      "spark.memory.storageFraction" = 0.90
      "spark.executor.memoryOverhead" = "384M"
      //spark.sql.shuffle.partitions = 500
      //spark.default.parallelism = 500
      //spark.executor.extraJavaOptions = "-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
      //spark.driver.extraJavaOptions = "-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
      //spark.dynamicAllocation.enabled = "true"
      //spark.shuffle.service.enabled = "true"
    }
    suites-parallel = false
    workload-suites = [
       {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g2-t-2.csv"
        parallel = false
        repeat = 1
        save-mode = "append"
        workloads = [
          {
            name = "sql"
            input = ["file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data2.csv", "file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data-g2-2.parquet"]
            query = ["select * from input", "select c0, c7, c6 from input where c0 < -0.9 and c7 < -0.9"]
            cache = false
            //partitions = p
            //output = "file:///opt/bitnami/spark/spark_data/spark-bench/output-sql-g2-t-2.parquet"
            save-mode = "overwrite"
          }
        ]
     }
    ]
   }]

}
