spark-bench = {
  spark-submit-parallel = false
  spark-submit-config = [{
    spark-args = {
      master = "spark://silver-spark-master-svc:7077"
      //silver-spark-master-svc.Namespace.svc.cluster.local:7077"
      executor-memory = "2G"
      //total-executor-cores = "26"
      //executor-cores = "2"
      driver-memory = "14G"
      //deploy-mode = "cluster"
      //num-executors = 2
    }
    conf = {
     //spark.memory.fraction = 0.75
     spark.memory.storageFraction = 0.90
     //spark.executor.memoryOverhead = "128"
     spark.driver.memoryOverhead = 1024 
     //spark.sql.shuffle.partitions = 500
     //spark.default.parallelism = 500
      //spark.executor.extraJavaOptions = "-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
      //spark.driver.extraJavaOptions = "-XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap"
      //spark.dynamicAllocation.enabled = "true"
    }
    suites-parallel = false
    workload-suites = [
     {
        descr = "Run two different SQL queries over the dataset in two different formats"
        benchmark-output = "file:///opt/bitnami/spark/spark_data/spark-bench/results-sql-g0-1.csv"
        parallel = false
        save-mode = "append"
        workloads = [
          {
            name = "data-generation-kmeans"
            rows = 10000
            cols = 25
            partitions = 10
            output = "file:///opt/bitnami/spark/spark_data/spark-bench-test/kmeans-data-g0-1.csv"
          }
        ]
     }
   ]
  }]
}
